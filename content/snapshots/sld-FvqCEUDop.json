{"i":{"FvqCEUDop":{"id":"FvqCEUDop","type":"slide","setup":{"bord":{"size":0,"rad":0},"bg":{"selectedKey":"image","fill":{"opac":1,"rgb":"var(--TC3)"},"img":{"filt":{"opac":100,"gray":0,"blur":0,"tint":{"rgb":"var(--TC3)","opac":0.5,"blendMode":"multiply"}},"pos":{"type":"crop","fit":{"bg":{"color":{"rgb":"#FFF","opac":100}},"vali":"center","hali":"center"},"crop":{"poi":{"x":557,"y":450}}},"measures":{"size":{"width":1080,"height":591}}}},"transparentBg":{"selectedKey":false}}},"uUSuFBNYbH":{"id":"uUSuFBNYbH","type":"interactive","subtype":"interactiveRichText","setup":{"frmeTp":{"selectedKey":"bottomLine"},"bg":{"selectedKey":"fill","fill":{"opac":0.2,"rgb":"#FFF"}},"txt":{"val":{"ops":[{"attributes":{"bold":true,"lang":"ES-US","color":"#124386","background":"rgba(0, 0, 0, 0)"},"insert":"Equilibrio entre sesgo y varianza"},{"insert":"\n","attributes":{"align":"center","size":"largeTitle"}}]},"rType":"richtext"},"vali":"middle","hali":"","frmeColo":{"color":{"opac":1,"rgb":"#124386"}}}},"sM_mNIqdH":{"id":"sM_mNIqdH","type":"interactive","subtype":"interactiveCoverFlow","setup":{"style":{"selectedKey":"textOverlapping"},"title":{"rType":"text","tag":"p"},"animation":{"selectedKey":"horizontal"},"imgs":{"i":{"EYOhk5pys":{"type":"image","id":"EYOhk5pys","txtBg":{"fill":{"opac":1,"rgb":"var(--TC14)"}},"img":{"filt":{"opac":100,"gray":0,"blur":0,"tint":{"rgb":"#FFF","opac":0}},"pos":{"type":"crop","fit":{"bg":{"color":{"rgb":"#FFF","opac":100},"gradient":{"angle":0,"opac":0.5,"stops":[{"color":"#000000","pos":0},{"color":"#000000","pos":100}]}},"vali":"center","hali":"center"},"crop":{"bg":{"color":{"rgb":"#FFF","opac":0},"gradient":{"angle":0,"opac":0.5,"stops":[{"color":"#000000","pos":0},{"color":"#000000","pos":100}]}},"poi":{"orig":{"x":50,"y":50},"cust":{"x":50,"y":50}}},"mask":{"shape":1,"bg":{"color":{"rgb":"#FFF","opac":0},"gradient":{"angle":0,"opac":0.5,"stops":[{"color":"#000000","pos":0},{"color":"#000000","pos":100}]}}}}},"desc":{"val":{"ops":[{"insert":"En modelos con sesgo elevado, el desempeño del modelo en el conjunto de validación se asemeja al rendimiento en el conjunto de entrenamiento. En cambio, en modelos con alta variabilidad, la eficacia del modelo en el conjunto de validación es notablemente inferior respecto al desempeño en el conjunto de entrenamiento.","attributes":{"color":"var(--TC13)","lang":"ES-ES"}},{"insert":" ","attributes":{"color":"var(--TC13)"}},{"insert":"\n","attributes":{"align":"justify"}},{"insert":" ","attributes":{"color":"var(--TC13)"}},{"insert":"\n","attributes":{"align":"justify"}},{"insert":"Si tomamos en cuenta que tenemos cierta capacidad para ajustar la complejidad del modelo, anticiparíamos que la puntuación de entrenamiento y la puntuación de validación se comporten de la siguiente manera, como se muestra en la figura:","attributes":{"lang":"ES-ES","color":"var(--TC13)"}},{"insert":"\n","attributes":{"align":"justify"}}]},"rType":"richtext","hali":"","paddV1":30}},"GWGR-DpRv":{"type":"image","id":"GWGR-DpRv","txtBg":{"fill":{"opac":0.8,"rgb":"var(--TC14)"}},"img":{"filt":{"opac":100,"gray":0,"blur":0,"tint":{"rgb":"#FFF","opac":0}},"pos":{"type":"crop","fit":{"bg":{"color":{"rgb":"#FFF","opac":100},"gradient":{"angle":0,"opac":0.5,"stops":[{"color":"#000000","pos":0},{"color":"#000000","pos":100}]}},"vali":"center","hali":"center"},"crop":{"bg":{"color":{"rgb":"#FFF","opac":0},"gradient":{"angle":0,"opac":0.5,"stops":[{"color":"#000000","pos":0},{"color":"#000000","pos":100}]}},"poi":{"orig":{"x":50,"y":50},"cust":{"x":50,"y":50}}},"mask":{"shape":1,"bg":{"color":{"rgb":"#FFF","opac":0},"gradient":{"angle":0,"opac":0.5,"stops":[{"color":"#000000","pos":0},{"color":"#000000","pos":100}]}}}}},"desc":{"val":{"ops":[{"insert":"El gráfico que se presenta comúnmente como la curva de validación tiene características esenciales. La puntuación de entrenamiento es siempre superior a la puntuación de validación. Esto es típico, ya que el modelo se ajustará mejor a los datos que ha visto en comparación con los datos no vistos.","attributes":{"color":"var(--TC13)","background":"#ffffff","lang":"ES-ES"}},{"insert":" ","attributes":{"color":"var(--TC13)","background":"#ffffff"}},{"insert":"\n","attributes":{"align":"justify","size":"normal"}}]},"rType":"richtext","paddV1":30,"hali":""}},"Tms1ut_jl":{"type":"image","id":"Tms1ut_jl","txtBg":{"fill":{"opac":1,"rgb":"var(--TC14)"}},"img":{"filt":{"opac":100,"gray":0,"blur":0,"tint":{"rgb":"#FFF","opac":0}},"pos":{"type":"crop","fit":{"bg":{"color":{"rgb":"#FFF","opac":100},"gradient":{"angle":0,"opac":0.5,"stops":[{"color":"#000000","pos":0},{"color":"#000000","pos":100}]}},"vali":"center","hali":"center"},"crop":{"bg":{"color":{"rgb":"#FFF","opac":0},"gradient":{"angle":0,"opac":0.5,"stops":[{"color":"#000000","pos":0},{"color":"#000000","pos":100}]}},"poi":{"orig":{"x":50,"y":50},"cust":{"x":50,"y":50}}},"mask":{"shape":1,"bg":{"color":{"rgb":"#FFF","opac":0},"gradient":{"angle":0,"opac":0.5,"stops":[{"color":"#000000","pos":0},{"color":"#000000","pos":100}]}}}}},"desc":{"val":{"ops":[{"insert":"En modelos de baja complejidad (alto sesgo), los datos de entrenamiento no se ajustan adecuadamente, lo que implica que el modelo es un predictor deficiente tanto para los datos de entrenamiento como para cualquier dato no visto previamente. Por otro lado, en un modelo de alta complejidad (alta varianza), los datos de entrenamiento están sobre ajustados, indicando que el modelo predice muy bien los datos de entrenamiento, pero falla en los datos no vistos previamente.","attributes":{"lang":"ES-ES","color":"var(--TC13)"}},{"insert":"\n","attributes":{"align":"justify"}}]},"rType":"richtext","hali":"","paddV1":30}},"w4J0gCWHl":{"type":"image","id":"w4J0gCWHl","txtBg":{"fill":{"opac":1,"rgb":"var(--TC14)"}},"img":{"filt":{"opac":100,"gray":0,"blur":0,"tint":{"rgb":"#FFF","opac":0}},"pos":{"type":"crop","fit":{"bg":{"color":{"rgb":"#FFF","opac":100},"gradient":{"angle":0,"opac":0.5,"stops":[{"color":"#000000","pos":0},{"color":"#000000","pos":100}]}},"vali":"center","hali":"center"},"crop":{"bg":{"color":{"rgb":"#FFF","opac":0},"gradient":{"angle":0,"opac":0.5,"stops":[{"color":"#000000","pos":0},{"color":"#000000","pos":100}]}},"poi":{"orig":{"x":50,"y":50},"cust":{"x":50,"y":50}}},"mask":{"shape":1,"bg":{"color":{"rgb":"#FFF","opac":0},"gradient":{"angle":0,"opac":0.5,"stops":[{"color":"#000000","pos":0},{"color":"#000000","pos":100}]}}}}},"desc":{"val":{"ops":[{"insert":"Existe un punto intermedio de complejidad en el cual la curva de validación alcanza su punto máximo. Este nivel de complejidad señala un equilibrio adecuado entre sesgo y varianza. Los métodos para ajustar la complejidad del modelo varían entre diferentes modelos; al analizar detalladamente los modelos individuales en secciones posteriores, exploraremos cómo cada modelo permite dicho ajuste.","attributes":{"color":"var(--TC13)"}},{"insert":"\n","attributes":{"align":"justify"}}]},"rType":"richtext","hali":"","paddV1":30}}},"p":["EYOhk5pys","GWGR-DpRv","Tms1ut_jl","w4J0gCWHl"]}}},"lt6d2lGo-":{"id":"lt6d2lGo-","type":"interactive","subtype":"interactiveImageText","setup":{"style":{"selectedKey":"overlapping"},"animation":{"selectedKey":false},"txtBg":{"fill":{"opac":0,"rgb":"#000"}},"bg":{"img":{"filt":{"opac":100,"gray":0,"blur":0,"tint":{"rgb":"#FFF","opac":0}},"pos":{"type":"fit","fit":{"bg":{"color":{"rgb":"#FFF","opac":100},"gradient":{"angle":0,"opac":0.5,"stops":[{"color":"#000000","pos":0},{"color":"#000000","pos":100}]}},"vali":"center","hali":"center","margin":38},"crop":{"bg":{"color":{"rgb":"#FFF","opac":0},"gradient":{"angle":0,"opac":0.5,"stops":[{"color":"#000000","pos":0},{"color":"#000000","pos":100}]}},"poi":{"x":234,"y":210}},"mask":{"shape":1,"bg":{"color":{"rgb":"#FFF","opac":0},"gradient":{"angle":0,"opac":0.5,"stops":[{"color":"#000000","pos":0},{"color":"#000000","pos":100}]}}}},"measures":{"size":{"width":563,"height":421}},"orig":{"rType":"asset","rSubType":"image","fileName":"44.png","fileSize":65176,"val":"mc-1f304bc037c867ad090d759e6ddcb4be.png","aid":"NyoIg5eFC"}}},"txt":{"val":{"ops":[{"insert":"Curva de validación esquemática","attributes":{"bold":true,"color":"var(--TC13)"}},{"insert":"\n","attributes":{"align":"center","size":"normal"}},{"insert":"\n\n\n\n\n\n\n\n\n\n\n\n\n","attributes":{"size":"normal"}},{"insert":"Nota. Tomado de ","attributes":{"script":"sub","color":"var(--TC13)","lang":"LA-LATN"}},{"insert":"Python Data Science Handbook","attributes":{"script":"sub","lang":"LA-LATN","color":"var(--TC13)","italic":true}},{"insert":".","attributes":{"script":"sub","lang":"LA-LATN","color":"var(--TC13)"}},{"insert":"\n","attributes":{"size":"small"}},{"insert":"Fuente:","attributes":{"script":"sub","lang":"ES-ES","color":"var(--TC13)"}},{"insert":" ","attributes":{"underline":true,"script":"sub","lang":"ES-ES","color":"var(--TC13)"}},{"insert":"https://jakevdp.github.io/PythonDataScienceHandbook/","attributes":{"underline":true,"script":"sub","color":"#0000ff","lang":"ES-ES","link":"https://jakevdp.github.io/PythonDataScienceHandbook/"}},{"insert":"\n","attributes":{"size":"small"}}]},"rType":"richtext"},"paddV1":7,"hali":""}}},"v":"1"}